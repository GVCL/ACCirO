{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.signal import argrelextrema\n",
    "from scipy.ndimage import rank_filter\n",
    "import scipy.stats as st\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "from gingerit.gingerit import GingerIt\n",
    "import pysbd, re # pip install pysbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO find the best fit distribution of histogram\n",
    "def best_fit_distribution(data, bins=200, ax=None):\n",
    "    \"\"\"Model data by finding best fit distribution to data\"\"\"\n",
    "    # Get histogram of original data\n",
    "    y, x = np.histogram(data, bins=bins, density=True)\n",
    "    x = (x + np.roll(x, -1))[:-1] / 2.0\n",
    "\n",
    "    # Distributions to check\n",
    "    DISTRIBUTIONS = [        \n",
    "        st.alpha,st.anglit,st.arcsine,st.beta,st.betaprime,st.bradford,st.burr,st.cauchy,st.chi,st.chi2,st.cosine,\n",
    "        st.dgamma,st.dweibull,st.erlang,st.expon,st.exponnorm,st.exponweib,st.exponpow,st.f,st.fatiguelife,st.fisk,\n",
    "        st.foldcauchy,st.foldnorm,st.frechet_r,st.frechet_l,st.genlogistic,st.genpareto,st.gennorm,st.genexpon,\n",
    "        st.genextreme,st.gausshyper,st.gamma,st.gengamma,st.genhalflogistic,st.gilbrat,st.gompertz,st.gumbel_r,\n",
    "        st.gumbel_l,st.halfcauchy,st.halflogistic,st.halfnorm,st.halfgennorm,st.hypsecant,st.invgamma,st.invgauss,\n",
    "        st.invweibull,st.johnsonsb,st.johnsonsu,st.ksone,st.kstwobign,st.laplace,st.levy,st.levy_l,st.levy_stable,\n",
    "        st.logistic,st.loggamma,st.loglaplace,st.lognorm,st.lomax,st.maxwell,st.mielke,st.nakagami,st.ncx2,st.ncf,\n",
    "        st.nct,st.norm,st.pareto,st.pearson3,st.powerlaw,st.powerlognorm,st.powernorm,st.rdist,st.reciprocal,\n",
    "        st.rayleigh,st.rice,st.recipinvgauss,st.semicircular,st.t,st.triang,st.truncexpon,st.truncnorm,st.tukeylambda,\n",
    "        st.uniform,st.vonmises,st.vonmises_line,st.wald,st.weibull_min,st.weibull_max,st.wrapcauchy\n",
    "    ]\n",
    "\n",
    "    # Best holders\n",
    "    best_distribution = st.norm\n",
    "    best_params = (0.0, 1.0)\n",
    "    best_sse = np.inf\n",
    "\n",
    "    # Estimate distribution parameters from data\n",
    "    for distribution in DISTRIBUTIONS:\n",
    "\n",
    "        # Try to fit the distribution\n",
    "        try:\n",
    "            # Ignore warnings from data that can't be fit\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.filterwarnings('ignore')\n",
    "\n",
    "                # fit dist to data\n",
    "                params = distribution.fit(data)\n",
    "\n",
    "                # Separate parts of parameters\n",
    "                arg = params[:-2]\n",
    "                loc = params[-2]\n",
    "                scale = params[-1]\n",
    "\n",
    "                # Calculate fitted PDF and error with fit in distribution\n",
    "                pdf = distribution.pdf(x, loc=loc, scale=scale, *arg)\n",
    "                sse = np.sum(np.power(y - pdf, 2.0))\n",
    "\n",
    "                # if axis pass in add to plot\n",
    "                try:\n",
    "                    if ax:\n",
    "                        pd.Series(pdf, x).plot(ax=ax)\n",
    "                    end\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "                # identify if this distribution is better\n",
    "                if best_sse > sse > 0:\n",
    "                    best_distribution = distribution\n",
    "                    best_params = params\n",
    "                    best_sse = sse\n",
    "\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return (best_distribution.name, best_params)\n",
    "\n",
    "\n",
    "# To get local maxima ans minima\n",
    "def predictTrend(hgt,ylabels,xlabel,bar_type,x_title,y_title,  inter):\n",
    "    trend_str = '' \n",
    "    xlbls = xlabel\n",
    "    local_max = argrelextrema(hgt, np.greater)\n",
    "    local_min = argrelextrema(hgt, np.less)\n",
    "    order = np.array([0] * len(xlbls))\n",
    "    order[local_min] = -1\n",
    "    order[local_max] = 1\n",
    "    \n",
    "    if  inter == False or np.count_nonzero(order)<2:\n",
    "        # In the case of interclass trends\n",
    "        if inter == True:\n",
    "            neg_count = len([num for num in hgt if num <= 0])\n",
    "            if neg_count>(len(hgt)-neg_count):\n",
    "                hgt = np.array([num*-1 for num in hgt])\n",
    "            trend_str=\". The bar height differnce between \"+ylabels[0]+\" and \"+ylabels[1]\n",
    "            if y_title != '_':\n",
    "                trend_str=\". The \"+y_title+\" differnce between \"+ylabels[0]+\" and \"+ylabels[1]  \n",
    "        elif ylabels =='Y':\n",
    "            trend_str=\". The Y axis value\"\n",
    "            if y_title != '_':\n",
    "                trend_str=\". The \"+y_title\n",
    "        elif ylabels =='freq':\n",
    "            trend_str=\". The frequency\"\n",
    "        else:\n",
    "            trend_str=\". The \"+ylabels\n",
    "            if y_title != '_':\n",
    "                trend_str=\". The \"+y_title+\" of \"+ylabels\n",
    "    \n",
    "        if list(order)==[0]*len(xlbls):\n",
    "            if(int(hgt[0])<int(hgt[1])):\n",
    "                trend_str += \" has an overall increasing trend\"\n",
    "                if( int(hgt[len(hgt)-2])>int(hgt[len(hgt)-1]) ):\n",
    "                    trend_str += \" till \"+str(xlbls[len(xlbls)-2])+\" and ends with a drop in \"+str(xlbls[len(xlbls)-1])\n",
    "                else:\n",
    "                    trend_str += \" from \"+str(xlbls[0])+\" to \"+str(xlbls[len(xlbls)-1])\n",
    "            elif(int(hgt[0])>int(hgt[1])):\n",
    "                trend_str += \" has an overall decreasing trend\"\n",
    "                if( int(hgt[len(hgt)-2])<int(hgt[len(hgt)-1]) ):\n",
    "                    trend_str += \" till \"+str(xlbls[len(xlbls)-2])+\" and ends with a peak in \"+str(xlbls[len(xlbls)-1])\n",
    "                else:\n",
    "                    trend_str += \" from \"+str(xlbls[0])+\" to \"+str(xlbls[len(xlbls)-1])\n",
    "            else:\n",
    "                if(int(hgt[0])!=int(hgt[len(hgt)-1])):\n",
    "                    trend_str += \" is uniform with \"+str(int(hgt[0]))+\" till \"+str(xlbls[len(xlbls)-2])+\" and finally ends with \"+str(int(hgt[len(hgt)-1]))+\" in \"+str(xlbls[len(xlbls)-1])\n",
    "                else:\n",
    "                    trend_str += \" is uniform with \"+str(int(hgt[0]))+\" throughout the entire period\"  \n",
    "        \n",
    "        elif np.count_nonzero(order)<4:\n",
    "            # speak about global maximum and min \n",
    "            ht= hgt.tolist()\n",
    "            xlbls2 = xlbls\n",
    "            xlbls2[ht.index(max(ht))] = str(xlbls[ht.index(max(ht))]) + ' the maximum value' \n",
    "            xlbls2[ht.index(min(ht))] = str(xlbls[ht.index(min(ht))]) + ' the minimum value' \n",
    "\n",
    "            trend_str += \" starts with \"+str(int(hgt[0]))+\" at \"+x_title+' '+str(xlbls2[0])+\" then \"\n",
    "            j=1\n",
    "            while j<len(order):      \n",
    "                if order[j]==-1:\n",
    "                    if list(order[:j])==[0]*j:\n",
    "                        trend_str += \"declines till \"+str(xlbls2[j])\n",
    "                    else: \n",
    "                        trend_str += \", followed by a decreasing trend till \"+str(xlbls2[j])\n",
    "                elif order[j]==1:\n",
    "                    if list(order[:j])==[0]*j:\n",
    "                        trend_str += \"increases till \"+str(xlbls2[j])\n",
    "                    else : \n",
    "                        trend_str += \", followed by an increasing trend till \"+str(xlbls2[j])\n",
    "                j+=1\n",
    "            if(order[j-2]!=0):\n",
    "                trend_str += \", and finally ends with \"+str(int(hgt[j-1]))+\" in \"+str(xlbls2[j-1])\n",
    "            else :\n",
    "                if(hgt[j-1]<hgt[j-2]):\n",
    "                    trend_str += \", and ends with a decreasing trend till \"+str(xlbls2[j-1])\n",
    "                else:\n",
    "                    trend_str += \", and ends with a decreasing trend till \"+str(xlbls2[j-1])\n",
    "            xlbls2[ht.index(max(ht))] = xlbls2[ht.index(max(ht))].replace(' the maximum value','')\n",
    "            xlbls2[ht.index(min(ht))] = xlbls2[ht.index(min(ht))].replace(' the minimum value','')\n",
    "        else:\n",
    "            #Just discuss the maximum and minmium value\n",
    "            ht= hgt.tolist()\n",
    "            trend_str += ' has it maximum and minmum values '+str(int(max(ht)))+' and '+str(int(min(ht)))+' at '+str(xlbls[ht.index(max(ht))])+', and '+str(xlbls[ht.index(min(ht))])+\" respectively\"\n",
    "\n",
    "    return trend_str\n",
    "\n",
    "def simplebarsumm(yvals,ylabels,slabs,bar_type,x_title,y_title, inter):\n",
    "    if len(slabs)>6 or inter == True:\n",
    "        # Speak about maxima and minima\n",
    "        Summ = predictTrend(yvals,ylabels,slabs,bar_type,x_title,y_title, inter)   \n",
    "    else :\n",
    "        if x_title=='_':\n",
    "            x_title = 'labels'\n",
    "        if str(slabs[0]).isnumeric():\n",
    "            Summ = '. For the '+str(x_title)+' ranging form '+str(slabs[0])+' - '+str(slabs[-1])+' at the interval '+str(abs(slabs[0]-slabs[1]))            \n",
    "            Summ += ', the '+str(y_title)\n",
    "            if not (ylabels == 'Y' or  ylabels == 'freq'):\n",
    "                Summ += \" of \"+ylabels\n",
    "            Summ += ' are '\n",
    "            for i in yvals[:-1]:\n",
    "                Summ += str(round(i,2))+', '\n",
    "            Summ += 'and '+str(round(yvals[-1],2))+' respectively'\n",
    "        else : \n",
    "            Summ = '. The '+str(y_title)\n",
    "            if not (ylabels == 'Y' or  ylabels == 'freq'):\n",
    "                Summ += \" of \"+ylabels\n",
    "            Summ += ' are '\n",
    "            for i in yvals[:-1]:\n",
    "                Summ += str(round(i,2))+', '\n",
    "            Summ += 'and '+str(round(yvals[-1],2))\n",
    "            Summ += ' for the '+str(x_title)+\" \"\n",
    "            for i in slabs[:-1]:\n",
    "                Summ += str(i)+', '\n",
    "            Summ += 'and '+str(slabs[-1])+' respectively'\n",
    "  \n",
    "    return Summ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentor = pysbd.Segmenter(language=\"en\", clean=False)\n",
    "subsegment_re = r'[^;:\\n•]+[;,:\\n•]?\\s*'\n",
    "\n",
    "def GrammerCorrect(par):\n",
    "    fixed = []\n",
    "    for sentence in segmentor.segment(par):\n",
    "        if len(sentence) < 300:\n",
    "            fixed.append(GingerIt().parse(sentence)['result'])\n",
    "        else:\n",
    "            subsegments = re.findall(subsegment_re, sentence)\n",
    "            if len(subsegments) == 1 or any(len(v) < 300 for v in subsegments):\n",
    "                # print(f'Skipped: {sentence}') // No grammar check possible\n",
    "                fixed.append(sentence)\n",
    "            else:\n",
    "                res = []\n",
    "                for s in subsegments:\n",
    "                    res.append(GingerIt().parse(s)['result'])\n",
    "                fixed.append(\"\".join(res))\n",
    "    return \" \".join(fixed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spie11 \n",
      " The plot depicts a Pie Graph illustrating food consumption rate in restaurant that compares across the following categories:  donuts, baguette, soft drink, onion ring, sausage, pretzel, pancake, with proportions 6.2%, 2.1%, 11.0%, 13.7%, 13.7%, 15.0%, 16.3%, respectively where pizza contributing to majority of 21.0% and bacon contributing to minority of 1.0%.\n",
      "________________________________________________________________________\n",
      "spie9 \n",
      " The plot depicts a Pie Graph illustrating production that compares across the following categories:  australia, dem rep congo, canada, ghana, china, philippines, south africa, mexico, ussr, with proportions 18.1%, 0.8%, 9.5%, 3.5%, 17.7%, 3.7%, 3.2%, 12.3%, 5.4%, respectively where united states contributing to majority of 25.0% and columbia contributing to minority of 0.7%.\n",
      "________________________________________________________________________\n",
      "spie8 \n",
      " The plot depicts a Pie Graph illustrating water usage that compares across the following categories:  flushing toilet, shaving, drinking water, washing dishes, load laundry, washing car, with proportions 15.1%, 19.7%, 12.9%, 6.3%, 11.2%, 9.4%, respectively where watering lawn contributing to majority of 20.4% and running dishwasher contributing to minority of 5.1%.\n",
      "________________________________________________________________________\n",
      "spie10 \n",
      " The plot depicts a Pie Graph illustrating wild life in rain forest 5 0y 9 0y that compares across the following categories:  monkey, panda, zebra, gorilla, leopard, wolf, antelope, bald eagle, with proportions 7.4%, 8.5%, 13.7%, 15.1%, 10.5%, 11.7%, 4.8%, 4.5%, respectively where walrus contributing to majority of 19.9% and 5 00 contributing to minority of 3.9%.\n",
      "________________________________________________________________________\n",
      "spie12 \n",
      " The plot depicts a Pie Graph illustrating herbs usage in kitchen that compares across the following categories:  basil, clove, olive, turmeric, ginger, onion, green chili, with proportions 4.0%, 18.8%, 7.4%, 15.2%, 12.1%, 11.0%, 8.5%, respectively where garlic contributing to majority of 20.9% and shallot contributing to minority of 2.1%.\n",
      "________________________________________________________________________\n",
      "spie13 \n",
      " The plot depicts a Pie Graph illustrating employment options in state that compares across the following categories:  computer programmer, veterinarian, factory worker, miner, teacher, real estate agent, bellboy, gas station attendant, speaker, delivery man, with proportions 4.1%, 7.9%, 11.2%, 11.9%, 9.6%, 4.5%, 10.1%, 9.1%, 5.4%, 9.1%, respectively where street vendor contributing to majority of 13.6% and office worker contributing to minority of 3.5%.\n",
      "________________________________________________________________________\n",
      "spie14 \n",
      " The plot depicts a Pie Graph illustrating causes of road accidents that compares across the following categories:  speedingl reckless driving, not wearing seat belt, rain or wet roads, potholes and bad road condition, with proportions 25.5%, 13.1%, 5.9%, 18.5%, respectively where drunk driving contributing to majority of 31.2% and breaking traffic rules contributing to minority of 5.8%.\n",
      "________________________________________________________________________\n",
      "spie15 \n",
      " The plot depicts a Pie Graph illustrating crime rates in city that compares across the following categories:  abduction, arson, assassination, assault, bigamy, blackmail, bribery, child abuse, with proportions 8.5%, 5.5%, 9.8%, 12.1%, 6.1%, 15.2%, 15.7%, 5.3%, respectively where corruption contributing to majority of 17.4% and bombing, and burglary contributing to minority of 2.1%.\n",
      "________________________________________________________________________\n",
      "spie1 \n",
      " The plot depicts a Pie Graph illustrating programming c language language usage among developers that compares across the following categories:  ctt, r language, matlab, with proportions 15.0%, 19.6%, 22.8%, respectively where python contributing to majority of 32.8% and c language contributing to minority of 9.8%.\n",
      "________________________________________________________________________\n",
      "spie3 \n",
      " The plot depicts a Pie Graph illustrating population density south index korea that compares across the following categories:  us, uk, germany, south korea, with proportions 18.6%, 24.6%, 16.7%, 9.3%, respectively where india contributing to majority of 27.8% and australia contributing to minority of 2.9%.\n",
      "________________________________________________________________________\n",
      "spie2 \n",
      " The plot depicts a Pie Graph illustrating monthly household expenses that compares across the following categories:  utilities, food, gas, education, with proportions 14.2%, 11.4%, 6.7%, 25.2%, respectively where mortgage contributing to majority of 38.1% and travel contributing to minority of 4.4%.\n",
      "________________________________________________________________________\n",
      "spie6 \n",
      " The plot depicts a Pie Graph illustrating popular games that compares across the following categories:  actionadventure, adventure, fighting, shooter, platforming games, realtime strategy games, with proportions 8.1%, 12.6%, 27.9%, 13.0%, 3.7%, 3.7%, respectively where escape contributing to majority of 28.0% and multiplayer battle contributing to minority of 3.1%.\n",
      "________________________________________________________________________\n",
      "spie7 \n",
      " The plot depicts a Pie Graph illustrating rainfall in india that compares across the following categories:  goa, gujarat, haryana, himachal pradesh, karnataka, madhya pradesh, with proportions 10.3%, 12.1%, 12.1%, 15.4%, 11.1%, 16.5%, respectively where kerala contributing to majority of 18.2% and jharkhand contributing to minority of 4.3%.\n",
      "________________________________________________________________________\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e5b43f3e5b18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0mSumm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGrammerCorrect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSumm\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m     \u001b[0mtext_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"FinalSummary_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgno\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSumm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-e74a05d765ac>\u001b[0m in \u001b[0;36mGrammerCorrect\u001b[0;34m(par)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msegmentor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mfixed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGingerIt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'result'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0msubsegments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubsegment_re\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gingerit/gingerit.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, text, verify)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         )\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/requests/models.py\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    908\u001b[0m                     \u001b[0;31m# used.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \"\"\"\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "path = \"/Users/daggubatisirichandana/PycharmProjects/chart_percept/LINE_PIE/SYNTHETIC_DATA/PIE_RESULTS/\"\n",
    "# path = \"/Users/daggubatisirichandana/PycharmProjects/chart_percept/LINE_PIE/SYNTHETIC_DATA/DOT_RESULTS/\"\n",
    "# path = \"/Users/daggubatisirichandana/PycharmProjects/chart_percept/LINE_PIE/SYNTHETIC_DATA/LINE_RESULTS/\"\n",
    "\n",
    "for file in glob.glob(path+\"*.csv\"):\n",
    "    imgno = file.split('/')[-1].split(\".\")[0].split(\"_\")[-1]\n",
    "    df = pd.read_csv(file)\n",
    "    xlabel = (df.loc[ : , list(df)[0]]).values\n",
    "    xlabs = []\n",
    "    xlabs2 = []\n",
    "    for i in xlabel:\n",
    "        if isinstance(i, np.float64):\n",
    "            xlabs += [int(round(i))]\n",
    "            xlabs2 += [int(round(i))]\n",
    "        else :\n",
    "            xlabs += [i] \n",
    "            xlabs2 += [i] \n",
    "    title = df['title'][0]\n",
    "    bar_type = df['bar_type'][0]\n",
    "\n",
    "    if bar_type == 'Pie':\n",
    "        Summ = 'The plot depicts a '+bar_type+' Graph'\n",
    "        if title !='_':\n",
    "            Summ += ' illustrating '+title\n",
    "            \n",
    "        ylabels = (df.loc[ : , list(df)[1]]).values\n",
    "    #     ylabels, xlabels = zip(*[(x, y) for x, y in sorted(zip(ylabels, xlabels), reverse = True)])\n",
    "        max_ids = [i for i in range(len(ylabels)) if ylabels[i]==max(ylabels)]\n",
    "        min_ids = [i for i in range(len(ylabels)) if ylabels[i]==min(ylabels)]\n",
    "        Summ += ' that compares across the following categories:  '\n",
    "        for i in range(0,len(xlabs)):\n",
    "            if i not in min_ids and i not in max_ids:\n",
    "                Summ += str(xlabs[i])+\", \" \n",
    "        Summ += 'with proportions '\n",
    "        for i in range(0,len(ylabels)):\n",
    "            if i not in min_ids and i not in max_ids:\n",
    "                Summ += str(ylabels[i])+\"%, \" \n",
    "        Summ += 'respectively where '      \n",
    "        for i in max_ids:\n",
    "            if len(max_ids)!=1 and i==max_ids[-1]:\n",
    "                Summ += 'and '\n",
    "            Summ += str(xlabs[i])\n",
    "            if len(max_ids)!=1 and i!=max_ids[-1]:\n",
    "                Summ += ', '\n",
    "        Summ += ' contributing to majority of '+str(ylabels[i])+'% and '\n",
    "        for i in min_ids:\n",
    "            if len(min_ids)!=1 and i==min_ids[-1]:\n",
    "                Summ += 'and '\n",
    "            Summ += str(xlabs[i])\n",
    "            if len(min_ids)!=1 and i!=min_ids[-1]:\n",
    "                Summ += ', '\n",
    "        Summ += ' contributing to minority of '+str(ylabels[i])+'%'          \n",
    "\n",
    "    else:\n",
    "        x_title = df['x-title'][0]\n",
    "        y_title = df['y-title'][0]\n",
    "        ylabels = list(df)[1:len(list(df))-4]\n",
    "        data = (df.loc[ : , ylabels]).values\n",
    "    \n",
    "        ### Visual Summary\n",
    "        #Speak about starting line with titles\n",
    "        Summ = 'The plot depicts a '+bar_type+' Graph'\n",
    "        if title !='_':\n",
    "            Summ += ' illustrating '+title\n",
    "        if x_title != '_' and y_title != '_':\n",
    "            Summ +='. The plot is between '+y_title+' on y-axis over '+x_title+' on the x-axis'\n",
    "        elif y_title != '_':\n",
    "            Summ +='. The plot is having '+y_title+' on y-axis'\n",
    "        elif x_title != '_':\n",
    "            Summ +='. The plot is having '+x_title+' on x-axis'\n",
    "        # speaking about legend\n",
    "        if 'Simple' not in bar_type:\n",
    "            Summ +=' for '\n",
    "            for i in range(len(ylabels)-1):\n",
    "                Summ += str(ylabels[i])+\", \"\n",
    "            Summ += \"and \"+str(ylabels[i+1])\n",
    "\n",
    "        # intra class differrences\n",
    "        for i in range(len(ylabels)):\n",
    "            Summ += simplebarsumm(data[:,i],ylabels[i],xlabs,bar_type,x_title,y_title,False)\n",
    "        Summ = Summ.replace(\"_ \", \"\")\n",
    "        Summ = Summ.replace(\"\\n\", \" \").replace('\\r', '')\n",
    "\n",
    "        # inter class differrences\n",
    "        if 'Simple' not in bar_type:\n",
    "            Summ2 = ''\n",
    "            for x,y in list(combinations(range(len(ylabels)), 2)):\n",
    "                Summ2 += simplebarsumm(data[:,x]-data[:,y],[ylabels[x],ylabels[y]],xlabs2,bar_type,x_title,y_title,True)\n",
    "            # Cummulative description in stacked bar\n",
    "            if ('Stacked' in bar_type) or bar_type == 'Dot Plot':\n",
    "                Summ2 += simplebarsumm(np.sum(data, axis=1),'all catogeries cummulatively',xlabs,bar_type,x_title,y_title, False)    \n",
    "            Summ2 = Summ2.replace(\"_ \", \"\")\n",
    "            Summ2 = Summ2.replace(\"\\n\", \" \").replace('\\r', '')\n",
    "            if len(Summ2)>2:\n",
    "                Summ = Summ +\".\\n\\t\"+ Summ2[2:]\n",
    "\n",
    "        ### Statistical Summary\n",
    "        if 'Simple' in  bar_type:\n",
    "            dat, xlabs= zip(*sorted(zip(np.round(data[:,0].tolist(), decimals=2), xlabs2), reverse=True))\n",
    "            if y_title != '_':\n",
    "                Summ += '. The overall mean and standard deviation values of '+y_title+' are '+str(round(sum(dat)/len(dat),2))+' and '+str(round(np.std(data[:,i]),2))+' respectively'          \n",
    "            else:\n",
    "                Summ += '. The overall mean and standard deviation values are '+str(round(sum(dat)/len(dat),2))+' and '+str(round(np.std(data[:,i]),2))+' respectively'          \n",
    "        # For Catogeorical Graphs\n",
    "        else:\n",
    "            # To represent ranges of all groups\n",
    "            if y_title != '_':\n",
    "                Summ += '. The standard deviation values of '+y_title+' for catogeries \\''\n",
    "            else:\n",
    "                Summ += '. The standard deviation values for catogeries \\''   \n",
    "            for i in range(len(ylabels)-1):         \n",
    "                Summ += str(ylabels[i])+'\\', ' \n",
    "            Summ += 'and \\''+str(ylabels[-1])+'\\' are ' \n",
    "            for i in range(len(ylabels)-1):         \n",
    "                Summ += str(round(np.std(data[:,i]),2))+', '       \n",
    "            Summ += 'and '+str(round(np.std(data[:,-1]),2))+' respectively '\n",
    "\n",
    "            # Check for Correlation \n",
    "            corr_mat = np.triu(df.iloc[:,1:len(list(df))-4].corr(method='spearman'), k=1)\n",
    "\n",
    "            x,y=np.nonzero(abs(corr_mat)>0.6)\n",
    "            # remove transtivity between items\n",
    "            found_trnas = False\n",
    "            test_dict = {}\n",
    "            for i in set(x):\n",
    "                test_dict[i] = [y[j] for j in range(len(x)) if i==x[j]]\n",
    "            for i in set(y):\n",
    "                if i not in test_dict:\n",
    "                    test_dict[i] = [x[j] for j in range(len(y)) if i==y[j]]\n",
    "                else :\n",
    "                    test_dict[i] += [x[j] for j in range(len(y)) if i==y[j]]\n",
    "            lst = [sorted([k]+v) for k, v in test_dict.items()]\n",
    "            if len(lst)>1 and (lst.count(lst[0]) == len(lst)):  \n",
    "                found_trnas = True\n",
    "                if len(x) == len([True for j in range(len(x)) if corr_mat[x[j],y[j]]>0]):\n",
    "                    Summ += '. The categories \\''\n",
    "                    for i in range(len(lst[0])-1):\n",
    "                        Summ += str(ylabels[lst[0][i]])+\"\\', \" \n",
    "                    Summ += \"and \\'\"+str(ylabels[lst[0][-1]])+'\\' are positively correlated with one another'     \n",
    "                elif len(x) == len([True for j in range(len(x)) if corr_mat[x[j],y[j]]<0]):\n",
    "                    Summ += '. The categories \\''\n",
    "                    for i in range(len(lst[0])-1):\n",
    "                        Summ += str(ylabels[lst[0][i]])+\"\\', \" \n",
    "                    Summ += \"and \\'\"+str(ylabels[lst[0][-1]])+'\\' are negatively correlated with one another'\n",
    "                else:\n",
    "                    found_trnas = False\n",
    "\n",
    "            for j in range(len(x)):\n",
    "                if not found_trnas:\n",
    "                    if corr_mat[x[j],y[j]]>0:\n",
    "                        Summ += '. The categories \\''+str(ylabels[x[j]])+\"\\' and \\'\"+str(ylabels[y[j]])+'\\' are positively correlated '     \n",
    "                    else:\n",
    "                        Summ += '. The categories \\''+str(ylabels[x[j]])+\"\\' and \\'\"+str(ylabels[y[j]])+'\\' are negatively correlated '\n",
    "                pos = np.count_nonzero((data[:,x[j]]-data[:,y[j]])>0)\n",
    "                neg = np.count_nonzero((data[:,x[j]]-data[:,y[j]])<0)\n",
    "                if y_title!= '_':\n",
    "                    t = ' the '+y_title+' of'\n",
    "                else:\n",
    "                    t = ''\n",
    "                if pos<neg and pos == 1:\n",
    "                    k = np.nonzero((data[:,x[j]]-data[:,y[j]])>0)[0][0]\n",
    "                    Summ += '. All except for '+str(xlabs[k])+t+' \\''+str(ylabels[y[j]])+'\\' is greater than \\''+str(ylabels[x[j]])+'\\''\n",
    "                elif neg<pos and neg == 1:\n",
    "                    k = np.nonzero((data[:,x[j]]-data[:,y[j]])<0)[0][0]\n",
    "                    Summ += '. All except for '+str(xlabs[k])+t+' \\''+str(ylabels[y[j]])+'\\' is lesser than \\'\\''+str(ylabels[x[j]])+'\\''\n",
    "                elif(np.count_nonzero((data[:,x[j]]-data[:,y[j]])<0) == 1):\n",
    "                    k = np.nonzero((data[:,x[j]]-data[:,y[j]])==0)[0][0]\n",
    "                    Summ += '. All except for '+str(xlabs[k])+t+' \\''+str(ylabels[y[j]])+'\\' is equal to \\''+str(ylabels[x[j]])+'\\''\n",
    "    #     if 'Dot' in bar_type:\n",
    "    #         Summ = Summ.replace(\"value\", \"count\")\n",
    "\n",
    "\n",
    "\n",
    "    Summ = GrammerCorrect(Summ+'.')\n",
    "    text_file = open(path+\"FinalSummary_\"+str(imgno)+\".txt\", \"w\")\n",
    "    n = text_file.write(Summ)\n",
    "    text_file.close()\n",
    "\n",
    "    print(imgno,\"\\n\",Summ)\n",
    "    print(\"________________________________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['about', 'is', '2099', 'lowest', '3968', 'highest', 'between', 'with', 'degree', 'and', 'd', 'celsius', 'c', 'which', '483', 'chart', 'relation', 'summer', 'image', 'ranges', 'the', 'temperature', 'has', '4-10', 'of', 'winters', 'e', 'describes', 'cities', 'whereas', 'in', 'experiences', 'five', 'chills', 'city', 'for', 'during', 'among', 'coldest']\n",
      "['on', 'is', 'y-axis', 'standard', 'values', '631', 'winter', 'depicts', 'plot', 'with', 'and', 'c', 'd', '925', 'having', 'deviation', 'illustrating', 'b', 'summer', '(*c)', 'list', '484', '2092', 'the', 'temperature', 'graph', 'from', 'of', 'bar', 'e', 'a', '168', 'vertical', 'city', 'grouped', 'for', 'to', '3944', 'range', 'x-axis']\n",
      "['', 'on', 'is', 'y-axis', 'till', 'standard', 'values', '631', 'winter', 'ends', 'minimum', 'depicts', 'plot', 'respectively', 'between', '12', 'with', 'increases', 'finally', '69', 'and', 'c', 'd', '925', 'having', '582', '876', 'deviation', 'difference', 'categories', '2562', 'maximum', 'starts', 'at', 'illustrating', 'value', '2444', 'b', 'summer', '(*c)', '484', '2092', '2778', 'the', 'temperature', 'then', 'graph', 'of', 'labels', 'bar', 'e', '16', 'a', 'in', '168', 'vertical', 'city', 'grouped', 'are', 'for', '3944']\n",
      "39 40 61 3.549225288188377e-155 9.74806386640271e-232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/nltk/translate/bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "# ### hb3\n",
    "# ref = 'The chart image describes the relation between abortion rate and different age groups. The age groups are shown are in the range of 10-45 with interval of 5. The highest abortion rate is shown by tallest bar representing the age group of 20.'\n",
    "# final = 'The plot depicts a Horizontal Simple Bar Graph illustrating Abortion Rate among different age groups.  The plot is between Age on y-axis over Abortion rate on the x-axis.  In the Age ranging form 15-40 at the interval 5, the Abortion rate are 22.8, 35.4, 24.2, 16.07, 11.07, and 3.73 respectively. The overall mean and standard deviation values of Abortion rate are 18.88 and 10.12 respectively.'\n",
    "# intial = 'The plot depicts a Horizontal Simple Bar Graph illustrating Abortion Rate among different age groups. The plot is between Age on y-axis over Abortion rate on the x-axis. The Abortion rate starts with 22 in 14 then increases till 19, followed by a decreasing trend till 39 the end'\n",
    "\n",
    "### gb03\n",
    "ref = 'The chart image describes about the relation between the highest temperature in summer and lowest temperature in winters for five cities. During summer, the temperature is highest in City D with 39.68 degree Celsius whereas city E has lowest temperature of 20.99 degree Celsius. During winters, the temperature ranges between 4-10 degree Celsius for the five cities among which city C experiences the coldest winters with the chills of 4.83 degree Celsius.'\n",
    "final = 'The plot depicts a Vertical Grouped Bar Graph illustrating City Temperature.  The plot is having Temperature (*C) on y-axis for summer, and winter.  The Temperature (*C) of summer are 25.62, 24.44, 27.78, 39.44, and 20.92 for the labels City A, City B, City C, City D, and City E respectively.  The Temperature (*C) of winter are 9.25, 5.82, 4.84, 6.9, and 8.76 for the labels City A, City B, City C, City D, and City E respectively. The Temperature (*C) difference between summer and winter starts with 16 at City at then increases till City D the maximum value, and finally ends with 12 in City E the minimum value.  The standard deviation values of Temperature (*C) for categories summer, and winter are 6.31, and 1.68 respectively.'\n",
    "intial = 'The plot depicts a Vertical Grouped Bar Graph illustrating City Temperature. The plot is having Temperature (*C) on y-axis for summer, and winter. The list of X-axis values is City A, City B, City C, City D, and City E. The summer range from 20.92 to 39.44, with a standard deviation of 6.31. The winter range from 4.84 to 9.25, with a standard deviation of 1.68'\n",
    "\n",
    "reference = ref.replace(\",\", \"\").replace('.', '').split(' ')\n",
    "reference = list(set(map(lambda x: x.lower(), reference)))\n",
    "candidatei = intial.replace(\",\", \"\").replace('.', '').split(' ')\n",
    "candidatei = list(set(map(lambda x: x.lower(), candidatei)))\n",
    "candidatef = final.replace(\",\", \"\").replace('.', '').split(' ')\n",
    "candidatef = list(set(map(lambda x: x.lower(), candidatef)))\n",
    "\n",
    "print(reference)\n",
    "print((candidatei))\n",
    "print(candidatef)\n",
    "scorei = sentence_bleu(reference, candidatei)\n",
    "scoref = sentence_bleu(reference, candidatef)\n",
    "print(len(reference), len(candidatei), len(candidatef),scorei,scoref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
